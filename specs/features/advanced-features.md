# Feature: Advanced Cloud & Event-Driven Architecture (Phase V)

## 1. Goal
Evolve the Todo application from a synchronous 2-tier app into a scalable, event-driven microservices architecture using Dapr and Kafka, deployable to DigitalOcean Kubernetes Service (DOKS).

## 2. Requirements

### A. Functional
- **Recurring Tasks:** Users can mark tasks as recurring (daily, weekly). When a recurring task is completed, a new instance is automatically created.
- **Reminders:** Users can set due dates. The system sends notifications (simulated logging) when a task is due.

### B. Technical
- **Dapr Integration:** Use Dapr for:
    - **State Management:** Abstracting PostgreSQL access (optional, or stick to SQLModel for main data, Dapr State for lightweight cursor/tracking). *Decision: Keep SQLModel for complex queries, use Dapr PubSub for events.*
    - **Pub/Sub:** Abstracting Kafka for event messaging.
- **Event-Driven Flow:**
    - `TaskCompleted` event -> `RecurringTaskEngine` -> `CreateTask` command.
    - `TaskDue` check -> `NotificationService`.
- **Infrastructure:**
    - **Kafka:** Strimzi Operator or Redpanda deployed via Helm.
    - **Dapr:** Dapr System Services deployed on cluster.
    - **Cloud:** DigitalOcean DOKS.

## 3. Architecture Components

### A. Core Services
1.  **Backend API (Existing):**
    -   *Update:* Publish `topic: todo-events` -> `TaskCreated`, `TaskCompleted`.
    -   *Update:* Listen to `topic: todo-commands` -> `CreateTask` (generated by engine).
2.  **Recurring Task Engine (New Service):**
    -   *Role:* Listens for `TaskCompleted`. Checks `recurrence_rule`. If present, calculates next date and publishes `CreateTask` command.
3.  **Notification Service (New Service):**
    -   *Role:* Scheduled job or listener. For this hackathon, it listens to `TaskCreated` (with due date) and schedules a deferred message or simply logs it.

### B. Dapr Components
1.  **`pubsub.kafka`:** Connects to the Kafka cluster.
2.  **`statestore.postgresql`:** Connects to NeonDB (or local Postgres) for persistence if needed by new services.

## 4. Implementation Plan

### Step 1: Dapr & Kafka Setup (Infrastructure)
-   Install Dapr on K8s.
-   Install Kafka (Strimzi/Redpanda) on K8s.
-   Define `components/kafka-pubsub.yaml`.

### Step 2: Backend Modification
-   Inject Dapr Client SDK into `backend/service.py`.
-   Publish event on `complete_task()`.

### Step 3: Recurring Task Engine
-   Create `backend/services/scheduler.py` (or separate container).
-   Implement logic: `on_receive(TaskCompleted)` -> `calculate_next` -> `publish(CreateTask)`.

### Step 4: Deployment
-   Update Helm Chart to include Dapr annotations (`dapr.io/enabled: "true"`).
-   Create CI/CD workflow (`.github/workflows/deploy.yaml`) for DigitalOcean.

## 5. Data Model Updates
Update `Task` model in `backend/models.py`:
-   `is_recurring`: boolean
-   `recurrence_interval`: string (e.g., "daily", "weekly")
-   `due_date`: datetime

## 6. Verification
-   **Local:** Run with `dapr run`.
-   **Cluster:** `kubectl get pods` shows sidecars. Logs show event processing.
